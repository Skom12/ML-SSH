{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed8a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d84a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b8f27",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b18bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(dir):                                                                                                  \n",
    "    r = []                                                                                                            \n",
    "    subdirs = [x[0] for x in os.walk(dir)]\n",
    "    for subdir in subdirs:\n",
    "        files = os.walk(subdir).__next__()[2]\n",
    "        if (len(files) > 0):                                                                                          \n",
    "            for file in files:\n",
    "                r.append(os.path.join(subdir, file))                   \n",
    "    return r\n",
    "\n",
    "def custom_split(x):\n",
    "    return [x[i:i+20].strip() for i in range(0, len(x), 20)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f92cd",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31410a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='./CSV_Data/Training'\n",
    "test_path='./CSV_Data/Performance Test'\n",
    "validation_path='./CSV_Data/Validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1d8be",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc45dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess:\n",
    "    def __init__(self,dir_path,start_index,end_index):\n",
    "        self.x=None\n",
    "        self.y = None\n",
    "        self.vocab= dict()\n",
    "        \n",
    "        self.load(dir_path,start_index,end_index)\n",
    "        self.tosplit()\n",
    "        self.build_vocab()\n",
    "        self.tokenize()\n",
    "        \n",
    "    def load(self,dir_path,start_index,end_index):\n",
    "        print('#### Loading files ####')\n",
    "        files=list_files(dir_path)\n",
    "        files.sort()\n",
    "        files=files[start_index:end_index]\n",
    "        dataframes=[]\n",
    "        req_cols=[\"hex_values\",\"class\"]\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            df = pd.read_csv(file,sep='\\t',usecols=req_cols)\n",
    "            dataframes.append(df)\n",
    "        data=pd.concat(dataframes,ignore_index=True)\n",
    "        self.y=data['class']\n",
    "        self.x=data['hex_values']\n",
    "    \n",
    "    def tosplit(self):\n",
    "        for idx, value in self.x.iteritems():\n",
    "            self.x[idx]=custom_split(value)\n",
    "          \n",
    "    def build_vocab(self):  \n",
    "        print('#### Building vocab ####')\n",
    "        i=1\n",
    "        for idx, value in self.x.iteritems():\n",
    "            for element in value:\n",
    "                if element in self.vocab:\n",
    "                    pass\n",
    "                else:\n",
    "                    self.vocab[element]=i\n",
    "                    i=i+1\n",
    "            \n",
    "    def tokenize(self):\n",
    "        print('#### Tokenization ####')\n",
    "        for idx, value in self.x.iteritems():\n",
    "            for i in range(len(value)):\n",
    "                value[i]=self.vocab[value[i]]\n",
    "                \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63d455",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dacb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification_set(Dataset):\n",
    "    def __init__(self,x,y):        \n",
    "        self.x=x\n",
    "        self.y=y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876b67ee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Loading files ####\n",
      "./CSV_Data/Training/basic-V_8_7_P1-16.csv\n",
      "./CSV_Data/Training/basic-V_8_7_P1-24.csv\n",
      "./CSV_Data/Training/basic-V_8_7_P1-32.csv\n",
      "./CSV_Data/Training/basic-V_8_7_P1-64.csv\n",
      "./CSV_Data/Training/basic-V_8_8_P1-16.csv\n",
      "./CSV_Data/Training/basic-V_8_8_P1-24.csv\n",
      "./CSV_Data/Training/basic-V_8_8_P1-32.csv\n",
      "./CSV_Data/Training/basic-V_8_8_P1-64.csv\n",
      "#### Building vocab ####\n",
      "#### Tokenization ####\n",
      "CPU times: user 35.7 s, sys: 2.64 s, total: 38.4 s\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data=preprocess(train_path,36,44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d945dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test_data=preprocess(test_path)\n",
    "# validation_data=preprocess(validation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c43581-e246-4ca5-9ffa-d86757878261",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set= classification_set(train_data.x,train_data.y)\n",
    "# test_set= classification_set(test_data.x,test_data.y)\n",
    "# validation_set= classification_set(validation_data.x,validation_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750558da-6eaa-48df-b61d-5169f8a4c6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345555"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa1a8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e076d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size)\n",
    "# test_dataloader = DataLoader(test_set, batch_size)\n",
    "# validation_dataloader = DataLoader(validation_set, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623fe691",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fae39e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4154507049.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [7]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def classifier(nn.ModuleList):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def classifier(nn.ModuleList):\n",
    "    def __init__(self):\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.kernel_1=2\n",
    "        self.kernel_2=3\n",
    "        self.kernel_3=4\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec099a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
